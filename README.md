Ground Truth Video AnnotatorThis tool is used to annotate "Success" sequences in videos, such as a block landing in a target zone. It uses a live YOLO model to draw the target zone on the video as you annotate.1. Setup & InstallationStep 1: Install DependenciesOpen your terminal and run the following command to install all required libraries:pip install ultralytics torch torchvision pandas numpy opencv-python Pillow
Step 2: File StructurePlace your files in a single folder as shown below. The script must be in the same directory as keypoint_detector.py and expects the model to be named best_model.pt./your_project_folder
  ├── annotate_video.py       <-- The main script
  ├── keypoint_detector.py    <-- Your detector class file
  ├── best_model.pt           <-- Your trained YOLO model
  └── my_video.mp4            <-- The video you want to annotate
2. How to UseStep 1: Run the ToolOpen your terminal, navigate to your project folder, and run the script. You must specify the video and the handedness (--R or --L).Example for Right-Handed:python annotate_video.py --video my_video.mp4 --R
Example for Left-Handed:python annotate_video.py --video my_video.mp4 --L
Command-Line Arguments:--video: (Required) The path to your video file.--R or --L: (Required) You must choose one to set the target compartment (Right or Left).--output: (Optional) Specify a CSV name. By default, it saves as [video_name]_sequence_annotations.csv.Step 2: Use the ControlsA video window will open. Use these keys to annotate:| Key | Function | Description || k | Next Frame | Advance video by 1 frame. || j | Prev Frame | Rewind video by 1 frame. || 1 | Mark START | Marks the beginning of a success attempt. || 2 | Mark STOP | Marks the end of the attempt and saves the pair. || q | Quit | Saves all annotations to the CSV and exits. |3. OutputThe script automatically generates a CSV file (e.g., my_video_sequence_annotations.csv) in your project folder with Start Frame and End Frame columns.
